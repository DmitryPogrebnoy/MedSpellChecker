{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAliKDQvhExv"
   },
   "source": [
    "# Prepear test dataset\n",
    "Format - {word}{several spaces}{answer-words separeted by comma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (21.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JtZvUWdZhFOf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from pandas) (1.21.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OZYmhZvuWLfa"
   },
   "outputs": [],
   "source": [
    "test_incorrect_file = open('data/test_sample_incorrect.txt', 'r', encoding=\"utf8\")\n",
    "test_incorrect_lines = test_incorrect_file.readlines()\n",
    "splitted_test_incorrect_lines = list(map(lambda x: x.split(maxsplit=1), test_incorrect_lines))\n",
    "test_incorrect_words = list(map(lambda x: x[0], splitted_test_incorrect_lines))\n",
    "test_incorrect_answers = list(map(lambda x: list(map(lambda y: y.strip(), x[1].split(', '))), splitted_test_incorrect_lines))\n",
    "test_df = pd.DataFrame(test_incorrect_words, columns=[\"test_word\"])\n",
    "test_df[\"answers\"] = test_incorrect_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "0P3kfs2dhj4q",
    "outputId": "1b7a854b-2395-4ddb-bf6f-8c6ee54b4ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_word</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>эктренном</td>\n",
       "      <td>[экстренном]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>синусовго</td>\n",
       "      <td>[синусового]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>даным</td>\n",
       "      <td>[данным, данный, данные]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>шнутография</td>\n",
       "      <td>[шунтография]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сникопальных</td>\n",
       "      <td>[синкопальных]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_word                   answers\n",
       "0     эктренном              [экстренном]\n",
       "1     синусовго              [синусового]\n",
       "2         даным  [данным, данный, данные]\n",
       "3   шнутография             [шунтография]\n",
       "4  сникопальных            [синкопальных]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word_list = test_df[\"test_word\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_answers = test_df[\"answers\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to found out what is a lexical precision and error precision???\n",
    "def check_result_precision(original_word_list, corrected_word_list, answer_word_list):\n",
    "    words_number = len(corrected_word_list)\n",
    "    correct_words_number = 0\n",
    "    print(\"original_word_list --- corrected_word --- answer_word_list\")\n",
    "    for i, corrected_word in enumerate(corrected_word_list):\n",
    "        print(f\"{original_word_list[i]} --- {corrected_word} --- {answer_word_list[i]}\")\n",
    "        if corrected_word in answer_word_list[i]:\n",
    "            correct_words_number += 1\n",
    "    print(f\"Right corrected words count - {correct_words_number} of {words_number} total\")\n",
    "    return correct_words_number/words_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "En1-fnjrUS7y"
   },
   "source": [
    "# Spellchecker prototype initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9NdfwQyUDcR",
    "outputId": "19f552b7-eaa9-4db6-f541-816ae713f3d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from gensim) (1.7.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from gensim) (1.21.4)\n",
      "Collecting python-levenshtein\n",
      "  Using cached python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from python-levenshtein) (57.0.0)\n",
      "Building wheels for collected packages: python-levenshtein\n",
      "  Building wheel for python-levenshtein (setup.py): started\n",
      "  Building wheel for python-levenshtein (setup.py): finished with status 'done'\n",
      "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.2-cp39-cp39-win_amd64.whl size=84125 sha256=bc8d5e51621a5e5ac096a054a3213af48915127b34ac26622474e408b0f14e0a\n",
      "  Stored in directory: c:\\users\\pogre\\appdata\\local\\pip\\cache\\wheels\\46\\4a\\6c\\164a1d9dd67c82d208f19d869ad0a517a0c5a6117f608c53e6\n",
      "Successfully built python-levenshtein\n",
      "Installing collected packages: python-levenshtein\n",
      "Successfully installed python-levenshtein-0.12.2\n",
      "Requirement already satisfied: stringdist in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2 \n",
    "!pip install gensim\n",
    "!pip install python-levenshtein\n",
    "!pip install stringdist\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Yt2npPadTbbH"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pymorphy2  # python -m pip install pymorphy2 #python -m pip install gensim\n",
    "import Levenshtein  # python -m pip install python-levenshtein\n",
    "import stringdist  # python -m pip install stringdist\n",
    "from scipy.special import softmax\n",
    "from gensim.models import FastText\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "class SpellChecker:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.total_word_dict = pickle.load(open(r'data/total_word_dict.pickle', 'rb'))\n",
    "        self.wordcount = pickle.load(open(r'data/wordcount.pickle', 'rb'))\n",
    "        self.model = FastText.load(r'data/cbow_model_new.model', mmap='r')\n",
    "\n",
    "    def normalize_word(self, word):\n",
    "        morph = pymorphy2.MorphAnalyzer()\n",
    "        return morph.parse(word)[0].normal_form\n",
    "\n",
    "    def check_for_correction(self, word):\n",
    "        if word in self.total_word_dict:\n",
    "            return word\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_double_word(self, word):\n",
    "        morph = pymorphy2.MorphAnalyzer()\n",
    "        for i in range(2, len(word)):\n",
    "            part_a = morph.parse(word[:i])[0].normal_form\n",
    "            part_b = morph.parse(word[i:len(word)])[0].normal_form\n",
    "            if part_a in self.total_word_dict and part_b in self.total_word_dict:\n",
    "                return [part_a, part_b]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def predict_fast_text(self, word):\n",
    "        if word in self.model.wv.key_to_index:\n",
    "            top_words = [w[0] for w in self.model.wv.most_similar(positive=[word], topn=1000000)]\n",
    "            top_scores = [w[1] for w in self.model.wv.most_similar(positive=[word], topn=1000000)]\n",
    "        else:\n",
    "            # print(f'No word {word} in model')\n",
    "            top_words = [w[0] for w in self.model.wv.most_similar(positive=[word], topn=1000000)]\n",
    "            top_scores = [w[1] for w in self.model.wv.most_similar(positive=[word], topn=1000000)]\n",
    "        return top_words, top_scores\n",
    "\n",
    "    def apply_fast_text(self, word, topn):\n",
    "        ft_words, ft_scores = self.predict_fast_text(word)\n",
    "        models_distances = pd.DataFrame(data=ft_scores, index=ft_words, columns=['FastText'])\n",
    "        models_distances['mean'] = models_distances.mean(axis=1)\n",
    "        return ft_words, ft_scores, models_distances\n",
    "\n",
    "    def calc_levenshtein(self, a, b, distance='dlevenshtein'):\n",
    "\n",
    "        if distance == 'levenshtein':\n",
    "            return Levenshtein.distance(a, b)\n",
    "\n",
    "        elif distance == 'dlevenshtein':\n",
    "            return stringdist.rdlevenshtein(a, b)\n",
    "\n",
    "    def apply_levenshtein(self, word, smax=False):\n",
    "        words = [word] * len(self.total_word_dict)\n",
    "        if smax:\n",
    "            levenshtein_scores = softmax(np.array(list(map(self.calc_levenshtein, words, self.total_word_dict))))\n",
    "        else:\n",
    "            levenshtein_scores = np.array(list(map(self.calc_levenshtein, words, self.total_word_dict)))\n",
    "\n",
    "        lev_min_score = np.array(levenshtein_scores).min()\n",
    "        index_list = list([np.where(levenshtein_scores == lev_min_score)])[0][0]\n",
    "        lev_words = [self.total_word_dict[idx] for idx in index_list]\n",
    "\n",
    "        return lev_words\n",
    "\n",
    "    def apply_levenshtein_and_model(self, word, topn):\n",
    "        # Apply fasttext model\n",
    "        ft_words, ft_scores, models_distances = self.apply_fast_text(word, self.model)\n",
    "        # Get topmost result from model\n",
    "        ft_top_words, ft_top_scores = ft_words[:topn], ft_scores[:topn]\n",
    "        # Apply Levenshtein distance\n",
    "        lev_words = self.apply_levenshtein(word, self.total_word_dict)\n",
    "\n",
    "        # For all the topmost results obtained from the fasttext model \n",
    "        wordcount_scores = [self.wordcount[self.wordcount['word'] == ft_word]['counter'].values[0]\\\n",
    "                                if not self.wordcount[self.wordcount['word'] == ft_word].empty else 0\\\n",
    "                            for ft_word in ft_top_words]\n",
    "        probas_lev = []\n",
    "        for lw in lev_words:\n",
    "            if not self.wordcount[self.wordcount['word'] == lw].empty:\n",
    "                probas_lev.append(self.wordcount[self.wordcount['word'] == lw]\\\n",
    "                                      ['counter'].values[0] / len(self.wordcount))\n",
    "            else:\n",
    "                probas_lev.append(0)\n",
    "\n",
    "        word_list = lev_words\n",
    "        word_list = list(set(word_list + [self.normalize_word(w) for w in word_list]))\n",
    "\n",
    "        try:\n",
    "            # print(models_distances)\n",
    "            corrected_word = models_distances['mean'].loc[word_list].argmax()\n",
    "        #\n",
    "        except (KeyError, ValueError) as e:\n",
    "            print(e)\n",
    "            print(f'Fast Text Exception for {word}', )\n",
    "            corrected_word = word_list[np.array(probas_lev).argmax()]\n",
    "\n",
    "        method_word = corrected_word\n",
    "        return method_word\n",
    "\n",
    "    def choose_between_double_and_single_words(self, double_word, method_word):\n",
    "        result_words = [None, None]\n",
    "        result_words[0] = ' '.join(double_word)\n",
    "        result_words[1] = method_word\n",
    "        result_probas = [0, 0]\n",
    "\n",
    "        if not self.wordcount[self.wordcount['word'] == method_word].empty:\n",
    "            result_probas[1] = self.wordcount[self.wordcount['word'] == method_word]\\\n",
    "                                   ['counter'].values[0] / len(self.wordcount)\n",
    "\n",
    "        double_probas = [0, 0]\n",
    "        if len(double_word) > 1:\n",
    "            for j, d_word in enumerate(double_word):\n",
    "                if not self.wordcount[self.wordcount['word'] == d_word].empty:\n",
    "                    double_probas[j] = self.wordcount[self.wordcount['word'] == d_word]\\\n",
    "                                           ['counter'].values[0] / len(self.wordcount)\n",
    "            result_probas[0] = np.mean(double_probas)\n",
    "\n",
    "            for d_word in double_word:\n",
    "                if d_word not in self.total_word_dict:\n",
    "                    result_probas[0] = 0\n",
    "\n",
    "            if sum(result_probas) == 0:\n",
    "                result_word = method_word\n",
    "            else:\n",
    "                result_word = result_words[np.array(result_probas).argmax()]\n",
    "\n",
    "        else:\n",
    "\n",
    "            result_word = method_word\n",
    "        return result_word\n",
    "\n",
    "    def correct_words(self, text, topn=10, method='Lev_dict_FT', extend_dict=False):\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # print(text)\n",
    "        # print(self.model.wv.key_to_index)\n",
    "        word_list = [word.lower() for word in text.split( ) if word.isalpha()]\n",
    "\n",
    "        correct_words = []\n",
    "        for i, word in tqdm(enumerate(word_list)):\n",
    "            print(\"Processed word - \" + word)\n",
    "            checked_word = self.check_for_correction(word)\n",
    "            if checked_word:\n",
    "                correct_words.append(checked_word)\n",
    "                print(checked_word)\n",
    "            else:\n",
    "                if not self.wordcount[self.wordcount['word'] == word].empty:\n",
    "                    word_frequency = self.wordcount[self.wordcount['word'] == word]['counter'].values[0]\n",
    "                else:\n",
    "                    word_frequency = 0\n",
    "\n",
    "                if extend_dict:\n",
    "                    total_word_dict = list(set(self.total_word_dict + list(self.wordcount['word'].values)))\n",
    "\n",
    "                if method == 'FastText':\n",
    "                    ft_words, ft_scores, models_distances = self.apply_fast_text(word, topn)\n",
    "                    method_word = ft_words[0]\n",
    "\n",
    "                elif method == 'Levenshtein_dict':\n",
    "                    lev_words = self.apply_levenshtein(word)\n",
    "                    lev_word = lev_words[0]\n",
    "                    method_word = lev_word\n",
    "\n",
    "                elif method == 'Levenshtein_top_ft':\n",
    "                    ft_words, ft_scores, models_distances = self.apply_fast_text(word, topn)\n",
    "                    lev_words = self.apply_levenshtein(word, ft_words)\n",
    "                    lev_word = lev_words[0]\n",
    "                    method_word = lev_word\n",
    "\n",
    "                elif method == 'Lev_dict_FT':\n",
    "                    method_word = self.apply_levenshtein_and_model(word, topn)\n",
    "                    print(method_word)\n",
    "                correct_words.append(method_word)\n",
    "                print(method_word)\n",
    "\n",
    "        return ' '.join(correct_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mRtM4gyjlWZ"
   },
   "source": [
    "# Test SpellChecker Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "7o9vhlRljB3d"
   },
   "outputs": [],
   "source": [
    "input_text_for_prototype = \" \".join(test_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'эктренном синусовго даным шнутография сникопальных посление ходавый анмнезе сентированный самоч перевдена стентированеим кардиол переведна догосптальном миним субфебриллитет загрудиные перферия течени оклюзия жнщина пциент зарегистирована сегмета клекте эпид интелектуально нижн прводилась неуст госптализирован вперые послеоперационом госпитализирова ухудщение рентг дальнешем троботическая многосоудистое миокрада сопрвождались дискмфорт потлтвостью левогожелудочка рание виед ангинозныеболи догоситальном ввполнен чаосв октазалась линика ммента проведеной выполненяи леченяи обтилась повтороно зарегистриованы отицает дальнейщем болисохраняются частичынм атерокслеротичсекая деньс назначаля проведеняи беспакоют гипертензи воленйбол болезн стенокардаа продолжалсь поворное ощуащет ангигнозного диагностичекой поддерживающией межлопаточнй бедреной гшрядки бассеине возлуха сенября постояная рекмоендовнао поврждения дискофморта импалнтирован неочетливая обесвеченный серце блезнь лергия ука изжга жение кашел рствор пациен пожлой лекарсво нпреносимость амупула гел конценрат рилиф чссс экгъ фибриляция желдочек хрон гиподин нерный сист диагоностика гипоксмия ледокоин блокато тахкардия малоинвозивный алация имь паражение тяжолый гастрапластика вс лешний орта клапа вент палый пирикард метральный ултразвук херург кордиолог килограм акенезия врхушка апекальный сгмент вес сьенка церкулярный сридиный калапаный апарат потология перекард праксимальный деаметр корекция аслажнение стрдать гепертонический болезн одоптировать получять кансервативный тичение пребование отбиление самачувствие уходшение месро пункцыя особеность шнут шнутирование готчина эхэ каранарный ортерия сначимый стинос гаспиализировать имья олмазов прдшствовать стинакардия пиринести ифаркт моикарда лакализация спразка дальнейшый хроническаянедостаточность инфарктмиокарда отузла нарушениеработы вминуту эндокриннойсистемы сердечныйритм узловаятахикардия основныефакторы остановкасердца фибрилляцияжелудочков счастотой'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_for_prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "i_0brGD5jZ7M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed word - фибрилляцияжелудочков\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:05, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6912/3950746233.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mspellchecker_prototype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSpellChecker\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mspellchecker_prototype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcorrect_words\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"фибрилляцияжелудочков\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0msplitted_result\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6912/1614690474.py\u001B[0m in \u001B[0;36mcorrect_words\u001B[1;34m(self, text, topn, method, extend_dict)\u001B[0m\n\u001B[0;32m    182\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m                 \u001B[1;32melif\u001B[0m \u001B[0mmethod\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'Lev_dict_FT'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 184\u001B[1;33m                     \u001B[0mmethod_word\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_levenshtein_and_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtopn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    185\u001B[0m                     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod_word\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    186\u001B[0m                 \u001B[0mcorrect_words\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod_word\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6912/1614690474.py\u001B[0m in \u001B[0;36mapply_levenshtein_and_model\u001B[1;34m(self, word, topn)\u001B[0m\n\u001B[0;32m     83\u001B[0m         \u001B[0mft_top_words\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mft_top_scores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mft_words\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mtopn\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mft_scores\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mtopn\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     84\u001B[0m         \u001B[1;31m# Apply Levenshtein distance\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 85\u001B[1;33m         \u001B[0mlev_words\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_levenshtein\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtotal_word_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     86\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     87\u001B[0m         \u001B[1;31m# For all the topmost results obtained from the fasttext model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6912/1614690474.py\u001B[0m in \u001B[0;36mapply_levenshtein\u001B[1;34m(self, word, smax)\u001B[0m\n\u001B[0;32m     67\u001B[0m         \u001B[0mwords\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtotal_word_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0msmax\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 69\u001B[1;33m             \u001B[0mlevenshtein_scores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msoftmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalc_levenshtein\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwords\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtotal_word_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m             \u001B[0mlevenshtein_scores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcalc_levenshtein\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwords\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtotal_word_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6912/1614690474.py\u001B[0m in \u001B[0;36mcalc_levenshtein\u001B[1;34m(self, a, b, distance)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mdistance\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'dlevenshtein'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mstringdist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrdlevenshtein\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_levenshtein\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mword\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msmax\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages\\stringdist\\pystringdist\\rdlevenshtein.py\u001B[0m in \u001B[0;36mrdlevenshtein\u001B[1;34m(source, target)\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[1;31m# Compute restricted Damerau-Levenshtein distance using helper function and\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[1;31m# return result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_levenshtein_compute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msource\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages\\stringdist\\pystringdist\\levenshtein_shared.py\u001B[0m in \u001B[0;36m_levenshtein_compute\u001B[1;34m(source, target, rd_flag)\u001B[0m\n\u001B[0;32m     45\u001B[0m             \u001B[0mdel_dist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mins_dist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m             \u001B[0msub_trans_cost\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0msource\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m             \u001B[0msub_dist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mj\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0msub_trans_cost\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "spellchecker_prototype = SpellChecker()\n",
    "result = spellchecker_prototype.correct_words(\"фибрилляцияжелудочков\")\n",
    "splitted_result = result.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6912/1049141082.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Symspellpy - https://github.com/mammothb/symspellpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting symspellpy\n",
      "  Downloading symspellpy-6.7.0-py3-none-any.whl (2.6 MB)\n",
      "Requirement already satisfied: numpy>=1.13.1 in c:\\users\\pogre\\desktop\\medical_text_nlp_web\\venv\\lib\\site-packages (from symspellpy) (1.21.4)\n",
      "Installing collected packages: symspellpy\n",
      "Successfully installed symspellpy-6.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U symspellpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Symspellpy lookup on basic dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_frequency_dict = 'symspell_data/ru-100k.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "def test_symspell_py_lookup(frequency_dict_path, input_word_list):\n",
    "    sym_spell_py = SymSpell()\n",
    "    sym_spell_py.load_dictionary(frequency_dict_path, 0, 1, encoding=\"UTF8\")\n",
    "\n",
    "    result = []\n",
    "    timer = tqdm(input_word_list)\n",
    "    for word in timer:\n",
    "        suggestions = sym_spell_py.lookup(word, Verbosity.TOP, max_edit_distance=2, include_unknown=True)\n",
    "        result.append(suggestions[0].term)\n",
    "    return {\"elapsed\" : timer.format_dict[\"elapsed\"], \"corrected_word_list\" : result}\n",
    "\n",
    "def test_symspell_py_lookup_compound(frequency_dict_path, input_word_list):\n",
    "    sym_spell_py = SymSpell()\n",
    "    sym_spell_py.load_dictionary('symspell_data/ru-100k.txt', 0, 1, encoding=\"UTF8\")\n",
    "\n",
    "    result = []\n",
    "    timer = tqdm(input_word_list)\n",
    "    for word in timer:\n",
    "        suggestions = sym_spell_py.lookup_compound(word, max_edit_distance=2)\n",
    "        result.append(suggestions[0].term)\n",
    "    return {\"elapsed\" : timer.format_dict[\"elapsed\"], \"corrected_word_list\" : result}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 5271.71it/s]\n"
     ]
    }
   ],
   "source": [
    "test_symspell_py_lookup_result = test_symspell_py_lookup(basic_frequency_dict, test_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elapsed': 0.03793835639953613,\n",
       " 'corrected_word_list': ['коренном',\n",
       "  'синусовго',\n",
       "  'данным',\n",
       "  'шнутография',\n",
       "  'сникопальных',\n",
       "  'последние',\n",
       "  'подавай',\n",
       "  'анамнезе',\n",
       "  'сентированный',\n",
       "  'самой',\n",
       "  'переведена',\n",
       "  'стентированеим',\n",
       "  'кардинал',\n",
       "  'переведена',\n",
       "  'догосптальном',\n",
       "  'синим',\n",
       "  'субфебриллитет',\n",
       "  'загрудиные',\n",
       "  'периферия',\n",
       "  'течение',\n",
       "  'иллюзия',\n",
       "  'женщина',\n",
       "  'пациент',\n",
       "  'зарегистрирована',\n",
       "  'сегмента',\n",
       "  'клетке',\n",
       "  'спид',\n",
       "  'интеллектуально',\n",
       "  'ниже',\n",
       "  'проводилась',\n",
       "  'несут',\n",
       "  'госптализирован',\n",
       "  'впервые',\n",
       "  'послеоперационном',\n",
       "  'госпитализирова',\n",
       "  'ухудшение',\n",
       "  'ренты',\n",
       "  'дальнейшем',\n",
       "  'троботическая',\n",
       "  'многосоудистое',\n",
       "  'миокарда',\n",
       "  'сопровождались',\n",
       "  'дискмфорт',\n",
       "  'потлтвостью',\n",
       "  'левогожелудочка',\n",
       "  'ранее',\n",
       "  'виде',\n",
       "  'ангинозныеболи',\n",
       "  'догоситальном',\n",
       "  'вполне',\n",
       "  'часов',\n",
       "  'оказалась',\n",
       "  'лирика',\n",
       "  'момента',\n",
       "  'проведено',\n",
       "  'выполнения',\n",
       "  'лечения',\n",
       "  'осталась',\n",
       "  'повторно',\n",
       "  'зарегистрированы',\n",
       "  'отрицает',\n",
       "  'дальнейшем',\n",
       "  'болисохраняются',\n",
       "  'частичным',\n",
       "  'атерокслеротичсекая',\n",
       "  'день',\n",
       "  'назначали',\n",
       "  'проведения',\n",
       "  'беспокоит',\n",
       "  'гипертензии',\n",
       "  'волейбол',\n",
       "  'болезни',\n",
       "  'стенокардаа',\n",
       "  'продолжалось',\n",
       "  'повторное',\n",
       "  'ощущает',\n",
       "  'ангигнозного',\n",
       "  'диагностической',\n",
       "  'поддерживающие',\n",
       "  'межлопаточнй',\n",
       "  'бедренной',\n",
       "  'грядки',\n",
       "  'бассейне',\n",
       "  'воздуха',\n",
       "  'сентября',\n",
       "  'постоянная',\n",
       "  'рекомендовано',\n",
       "  'повреждения',\n",
       "  'дискофморта',\n",
       "  'импалнтирован',\n",
       "  'неочетливая',\n",
       "  'обеспеченных',\n",
       "  'сердце',\n",
       "  'болезнь',\n",
       "  'сергия',\n",
       "  'ука',\n",
       "  'из-за',\n",
       "  'жене',\n",
       "  'нашел',\n",
       "  'раствор',\n",
       "  'пациент',\n",
       "  'пожилой',\n",
       "  'лекарство',\n",
       "  'нпреносимость',\n",
       "  'ампулы',\n",
       "  'дел',\n",
       "  'концентрат',\n",
       "  'или',\n",
       "  'ссср',\n",
       "  'экг',\n",
       "  'фибриляция',\n",
       "  'желдочек',\n",
       "  'крон',\n",
       "  'господин',\n",
       "  'черный',\n",
       "  'сист',\n",
       "  'диагностика',\n",
       "  'гипоксии',\n",
       "  'ледокол',\n",
       "  'блока',\n",
       "  'тахкардия',\n",
       "  'малоинвозивный',\n",
       "  'акация',\n",
       "  'им',\n",
       "  'поражение',\n",
       "  'тяжелый',\n",
       "  'гастрапластика',\n",
       "  'в',\n",
       "  'летний',\n",
       "  'сорта',\n",
       "  'клапан',\n",
       "  'сент',\n",
       "  'малый',\n",
       "  'пирикард',\n",
       "  'центральный',\n",
       "  'ультразвук',\n",
       "  'хирург',\n",
       "  'кордиолог',\n",
       "  'килограмм',\n",
       "  'акенезия',\n",
       "  'верхушка',\n",
       "  'печальный',\n",
       "  'сегмент',\n",
       "  'вес',\n",
       "  'стенка',\n",
       "  'церкулярный',\n",
       "  'средины',\n",
       "  'клапаны',\n",
       "  'аппарат',\n",
       "  'патология',\n",
       "  'перепад',\n",
       "  'максимальный',\n",
       "  'диаметр',\n",
       "  'коррекция',\n",
       "  'наслаждение',\n",
       "  'страдать',\n",
       "  'гипертонической',\n",
       "  'болезни',\n",
       "  'одоптировать',\n",
       "  'получить',\n",
       "  'консервативный',\n",
       "  'течение',\n",
       "  'требование',\n",
       "  'отделение',\n",
       "  'самочувствие',\n",
       "  'ухудшение',\n",
       "  'место',\n",
       "  'функция',\n",
       "  'особенность',\n",
       "  'шут',\n",
       "  'шнутирование',\n",
       "  'вотчина',\n",
       "  'эх',\n",
       "  'каранарный',\n",
       "  'артерия',\n",
       "  'значимый',\n",
       "  'стихов',\n",
       "  'гаспиализировать',\n",
       "  'имя',\n",
       "  'алмазов',\n",
       "  'предшествовать',\n",
       "  'стинакардия',\n",
       "  'принести',\n",
       "  'инфаркт',\n",
       "  'миокарда',\n",
       "  'локализация',\n",
       "  'справка',\n",
       "  'дальнейшей',\n",
       "  'хроническаянедостаточность',\n",
       "  'инфарктмиокарда',\n",
       "  'отдела',\n",
       "  'нарушениеработы',\n",
       "  'минуту',\n",
       "  'эндокриннойсистемы',\n",
       "  'сердечныйритм',\n",
       "  'узловаятахикардия',\n",
       "  'основныефакторы',\n",
       "  'остановкасердца',\n",
       "  'фибрилляцияжелудочков',\n",
       "  'частотой']}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_symspell_py_lookup_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "коренном --- ['экстренном']\n",
      "синусовго --- ['синусового']\n",
      "данным --- ['данным', 'данный', 'данные']\n",
      "шнутография --- ['шунтография']\n",
      "сникопальных --- ['синкопальных']\n",
      "последние --- ['поселение', 'последний']\n",
      "подавай --- ['ходовый']\n",
      "анамнезе --- ['анамнезе', 'анамнез']\n",
      "сентированный --- ['стентированный']\n",
      "самой --- ['самочувствие']\n",
      "переведена --- ['переведена']\n",
      "стентированеим --- ['стентированием', 'стентирование']\n",
      "кардинал --- ['кардиолог,кардиологический']\n",
      "переведена --- ['переведена']\n",
      "догосптальном --- ['догоспитальном']\n",
      "синим --- ['минимум', 'минимальный']\n",
      "субфебриллитет --- ['субфебрилитет']\n",
      "загрудиные --- ['загрудинные', 'загрудинный']\n",
      "периферия --- ['периферия']\n",
      "течение --- ['течение']\n",
      "иллюзия --- ['окклюзия']\n",
      "женщина --- ['женщина']\n",
      "пациент --- ['пациент']\n",
      "зарегистрирована --- ['зарегистрирована']\n",
      "сегмента --- ['сегмента']\n",
      "клетке --- ['клетке']\n",
      "спид --- ['эпидемия', 'эпидемиологический', 'эпидуральный']\n",
      "интеллектуально --- ['интеллектуально']\n",
      "ниже --- ['нижний']\n",
      "проводилась --- ['проводилась', 'проводить']\n",
      "несут --- ['неустановленный']\n",
      "госптализирован --- ['госпитализирован']\n",
      "впервые --- ['впервые']\n",
      "послеоперационном --- ['послеоперационном']\n",
      "госпитализирова --- ['госпитализирован']\n",
      "ухудшение --- ['ухудшение']\n",
      "ренты --- ['рентген']\n",
      "дальнейшем --- ['дальнейшем']\n",
      "троботическая --- ['тромботическая']\n",
      "многосоудистое --- ['многососудистое', 'многососудистый']\n",
      "миокарда --- ['миокарда', 'миокард']\n",
      "сопровождались --- ['сопровождались']\n",
      "дискмфорт --- ['дискомфорт']\n",
      "потлтвостью --- ['потливостью']\n",
      "левогожелудочка --- ['левого желудочка', 'левый желудочек']\n",
      "ранее --- ['ранее', 'ранние']\n",
      "виде --- ['виде', 'вид']\n",
      "ангинозныеболи --- ['ангинозные боли', 'ангиозный боль']\n",
      "догоситальном --- ['догоспитальном']\n",
      "вполне --- ['выполнен']\n",
      "часов --- ['часов']\n",
      "оказалась --- ['отказалась']\n",
      "лирика --- ['клиника']\n",
      "момента --- ['момента']\n",
      "проведено --- ['проведенной']\n",
      "выполнения --- ['выполнения', 'выполнение']\n",
      "лечения --- ['лечения', 'лечение']\n",
      "осталась --- ['обратилась']\n",
      "повторно --- ['повторно']\n",
      "зарегистрированы --- ['зарегистрированы']\n",
      "отрицает --- ['отрицает', 'отрицать']\n",
      "дальнейшем --- ['дальнейшем']\n",
      "болисохраняются --- ['боли сохраняются']\n",
      "частичным --- ['частичным']\n",
      "атерокслеротичсекая --- ['атеросклеротическая']\n",
      "день --- ['день', 'день с']\n",
      "назначали --- ['назначался']\n",
      "проведения --- ['проведения']\n",
      "беспокоит --- ['беспокоят']\n",
      "гипертензии --- ['гипертензия']\n",
      "волейбол --- ['волейбол']\n",
      "болезни --- ['болезнь']\n",
      "стенокардаа --- ['стенокардия']\n",
      "продолжалось --- ['продолжалась']\n",
      "повторное --- ['повторное']\n",
      "ощущает --- ['ощущает']\n",
      "ангигнозного --- ['ангинозного', 'ангинозный']\n",
      "диагностической --- ['диагностической', 'диагностический']\n",
      "поддерживающие --- ['поддерживающий']\n",
      "межлопаточнй --- ['межлопаточный']\n",
      "бедренной --- ['бедренной', 'бедренный']\n",
      "грядки --- ['грядки']\n",
      "бассейне --- ['бассейне', 'бассейн']\n",
      "воздуха --- ['воздуха', 'воздух']\n",
      "сентября --- ['сентября', 'сентябрь']\n",
      "постоянная --- ['постоянная', 'постоянный']\n",
      "рекомендовано --- ['рекомендовано']\n",
      "повреждения --- ['повреждения']\n",
      "дискофморта --- ['дискомфорт']\n",
      "импалнтирован --- ['имплантирован', 'имплантировать']\n",
      "неочетливая --- ['неотчетливая', 'неотчетливый']\n",
      "обеспеченных --- ['обесцвеченный', 'обеспеченный']\n",
      "сердце --- ['сердце']\n",
      "болезнь --- ['болезнь']\n",
      "сергия --- ['аллергия']\n",
      "ука --- ['рука']\n",
      "из-за --- ['изжога']\n",
      "жене --- ['жжение']\n",
      "нашел --- ['кашель']\n",
      "раствор --- ['раствор']\n",
      "пациент --- ['пациент']\n",
      "пожилой --- ['пожилой']\n",
      "лекарство --- ['лекарство']\n",
      "нпреносимость --- ['непереносимость']\n",
      "ампулы --- ['ампула']\n",
      "дел --- ['гель']\n",
      "концентрат --- ['концентрат']\n",
      "или --- ['релиф']\n",
      "ссср --- ['ЧСС', 'чсс']\n",
      "экг --- ['ЭКГ', 'экг']\n",
      "фибриляция --- ['фибрилляция']\n",
      "желдочек --- ['желудочек']\n",
      "крон --- ['хронический']\n",
      "господин --- ['гиподинамический']\n",
      "черный --- ['нервный']\n",
      "сист --- ['система']\n",
      "диагностика --- ['диагностика']\n",
      "гипоксии --- ['гипоксемия']\n",
      "ледокол --- ['лидокаин']\n",
      "блока --- ['блокатор']\n",
      "тахкардия --- ['тахикардия']\n",
      "малоинвозивный --- ['малоинвазивный']\n",
      "акация --- ['аблация', 'абляция']\n",
      "им --- ['ИМ', 'им']\n",
      "поражение --- ['поражение']\n",
      "тяжелый --- ['тяжелый']\n",
      "гастрапластика --- ['гастропластика']\n",
      "в --- ['вес']\n",
      "летний --- ['лишний']\n",
      "сорта --- ['аорта']\n",
      "клапан --- ['клапан']\n",
      "сент --- ['вена']\n",
      "малый --- ['полый']\n",
      "пирикард --- ['перикард']\n",
      "центральный --- ['митральный']\n",
      "ультразвук --- ['ультразвук']\n",
      "хирург --- ['хирург']\n",
      "кордиолог --- ['кардиолог']\n",
      "килограмм --- ['килограмм']\n",
      "акенезия --- ['акинезия']\n",
      "верхушка --- ['верхушка']\n",
      "печальный --- ['апикальный']\n",
      "сегмент --- ['сегмент']\n",
      "вес --- ['весь']\n",
      "стенка --- ['стенка']\n",
      "церкулярный --- ['циркулярный']\n",
      "средины --- ['срединный']\n",
      "клапаны --- ['клапанный']\n",
      "аппарат --- ['аппарат']\n",
      "патология --- ['патология']\n",
      "перепад --- ['перикард']\n",
      "максимальный --- ['проксимальный']\n",
      "диаметр --- ['диаметр']\n",
      "коррекция --- ['коррекция']\n",
      "наслаждение --- ['осложнение']\n",
      "страдать --- ['страдать']\n",
      "гипертонической --- ['гипертонический']\n",
      "болезни --- ['болезнь']\n",
      "одоптировать --- ['адаптировать']\n",
      "получить --- ['получать']\n",
      "консервативный --- ['консервативный']\n",
      "течение --- ['течение']\n",
      "требование --- ['пребывание']\n",
      "отделение --- ['отделение']\n",
      "самочувствие --- ['самочувствие']\n",
      "ухудшение --- ['ухудшение']\n",
      "место --- ['место']\n",
      "функция --- ['пункция']\n",
      "особенность --- ['особенность']\n",
      "шут --- ['шунт']\n",
      "шнутирование --- ['шунтирование']\n",
      "вотчина --- ['гатчина']\n",
      "эх --- ['эхо']\n",
      "каранарный --- ['коронарный']\n",
      "артерия --- ['артерия']\n",
      "значимый --- ['значимый']\n",
      "стихов --- ['стеноз']\n",
      "гаспиализировать --- ['госпитализировать']\n",
      "имя --- ['имя']\n",
      "алмазов --- ['алмазов']\n",
      "предшествовать --- ['предшествовать']\n",
      "стинакардия --- ['стенокардия']\n",
      "принести --- ['перенести']\n",
      "инфаркт --- ['инфаркт']\n",
      "миокарда --- ['миокарда']\n",
      "локализация --- ['локализация']\n",
      "справка --- ['справка']\n",
      "дальнейшей --- ['дальнейший']\n",
      "хроническаянедостаточность --- ['хроническая недостаточность', 'хронический недостаточность']\n",
      "инфарктмиокарда --- ['инфаркт миокарда', 'инфаркт миокард']\n",
      "отдела --- ['от узла', 'от узел']\n",
      "нарушениеработы --- ['нарушение работы', 'нарушение работа']\n",
      "минуту --- ['в минуту', 'в минута', 'минута']\n",
      "эндокриннойсистемы --- ['эндокринная система', 'эндокринный система']\n",
      "сердечныйритм --- ['сердечный ритм']\n",
      "узловаятахикардия --- ['узловая тахикардия', 'узловой тахикардия']\n",
      "основныефакторы --- ['основной факто', 'основные факторы']\n",
      "остановкасердца --- ['остановка сердца', 'остановка сердце']\n",
      "фибрилляцияжелудочков --- ['фибрилляция желудочков', 'фибрилляция желудочек']\n",
      "частотой --- ['с частотой', 'с частотаб частота']\n",
      "Right corrected words count - 84 of 200 total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_result_precision(test_word_list, test_symspell_py_lookup_result[\"corrected_word_list\"], test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 207.59it/s]\n"
     ]
    }
   ],
   "source": [
    "test_symspell_py_lookup_compound_result = test_symspell_py_lookup_compound(basic_frequency_dict, test_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "коренном --- ['экстренном']\n",
      "синус его --- ['синусового']\n",
      "данным --- ['данным', 'данный', 'данные']\n",
      "и фотография --- ['шунтография']\n",
      "они локальных --- ['синкопальных']\n",
      "последние --- ['поселение', 'последний']\n",
      "ход вый --- ['ходовый']\n",
      "анамнезе --- ['анамнезе', 'анамнез']\n",
      "центров данный --- ['стентированный']\n",
      "самой --- ['самочувствие']\n",
      "переведена --- ['переведена']\n",
      "стен титрованием --- ['стентированием', 'стентирование']\n",
      "кардинал --- ['кардиолог,кардиологический']\n",
      "переведена --- ['переведена']\n",
      "до остальном --- ['догоспитальном']\n",
      "синим --- ['минимум', 'минимальный']\n",
      "себе бриллиант --- ['субфебрилитет']\n",
      "за рудные --- ['загрудинные', 'загрудинный']\n",
      "периферия --- ['периферия']\n",
      "течение --- ['течение']\n",
      "иллюзия --- ['окклюзия']\n",
      "женщина --- ['женщина']\n",
      "пациент --- ['пациент']\n",
      "зарегистрирована --- ['зарегистрирована']\n",
      "сегмента --- ['сегмента']\n",
      "клетке --- ['клетке']\n",
      "спид --- ['эпидемия', 'эпидемиологический', 'эпидуральный']\n",
      "интеллектуально --- ['интеллектуально']\n",
      "ниже --- ['нижний']\n",
      "проводилась --- ['проводилась', 'проводить']\n",
      "несут --- ['неустановленный']\n",
      "госпитали мировая --- ['госпитализирован']\n",
      "впервые --- ['впервые']\n",
      "послеоперационном --- ['послеоперационном']\n",
      "госпитали кирова --- ['госпитализирован']\n",
      "ухудшение --- ['ухудшение']\n",
      "ренты --- ['рентген']\n",
      "дальнейшем --- ['дальнейшем']\n",
      "ты оптическая --- ['тромботическая']\n",
      "много сосудистой --- ['многососудистое', 'многососудистый']\n",
      "миокарда --- ['миокарда', 'миокард']\n",
      "сопровождались --- ['сопровождались']\n",
      "диск форт --- ['дискомфорт']\n",
      "после костью --- ['потливостью']\n",
      "левого желудочка --- ['левого желудочка', 'левый желудочек']\n",
      "ранее --- ['ранее', 'ранние']\n",
      "виде --- ['виде', 'вид']\n",
      "ангинозныеболи --- ['ангинозные боли', 'ангиозный боль']\n",
      "до остальном --- ['догоспитальном']\n",
      "вполне --- ['выполнен']\n",
      "часов --- ['часов']\n",
      "оказалась --- ['отказалась']\n",
      "лирика --- ['клиника']\n",
      "момента --- ['момента']\n",
      "проведено --- ['проведенной']\n",
      "выполнения --- ['выполнения', 'выполнение']\n",
      "лечения --- ['лечения', 'лечение']\n",
      "осталась --- ['обратилась']\n",
      "повторно --- ['повторно']\n",
      "зарегистрированы --- ['зарегистрированы']\n",
      "отрицает --- ['отрицает', 'отрицать']\n",
      "дальнейшем --- ['дальнейшем']\n",
      "боли сохраняются --- ['боли сохраняются']\n",
      "частичным --- ['частичным']\n",
      "атеросклероз этическая --- ['атеросклеротическая']\n",
      "день --- ['день', 'день с']\n",
      "назначали --- ['назначался']\n",
      "проведения --- ['проведения']\n",
      "беспокоит --- ['беспокоят']\n",
      "гипертензии --- ['гипертензия']\n",
      "волейбол --- ['волейбол']\n",
      "болезни --- ['болезнь']\n",
      "стенок рада --- ['стенокардия']\n",
      "продолжалось --- ['продолжалась']\n",
      "повторное --- ['повторное']\n",
      "ощущает --- ['ощущает']\n",
      "ан грозного --- ['ангинозного', 'ангинозный']\n",
      "диагностической --- ['диагностической', 'диагностический']\n",
      "поддерживающие --- ['поддерживающий']\n",
      "меж лопатой --- ['межлопаточный']\n",
      "бедренной --- ['бедренной', 'бедренный']\n",
      "грядки --- ['грядки']\n",
      "бассейне --- ['бассейне', 'бассейн']\n",
      "воздуха --- ['воздуха', 'воздух']\n",
      "сентября --- ['сентября', 'сентябрь']\n",
      "постоянная --- ['постоянная', 'постоянный']\n",
      "рекомендовано --- ['рекомендовано']\n",
      "повреждения --- ['повреждения']\n",
      "диском рта --- ['дискомфорт']\n",
      "импалнтирован --- ['имплантирован', 'имплантировать']\n",
      "не отчетливая --- ['неотчетливая', 'неотчетливый']\n",
      "обеспеченных --- ['обесцвеченный', 'обеспеченный']\n",
      "сердце --- ['сердце']\n",
      "болезнь --- ['болезнь']\n",
      "сергия --- ['аллергия']\n",
      "ука --- ['рука']\n",
      "из га --- ['изжога']\n",
      "жене --- ['жжение']\n",
      "нашел --- ['кашель']\n",
      "раствор --- ['раствор']\n",
      "пациент --- ['пациент']\n",
      "пожилой --- ['пожилой']\n",
      "лекарство --- ['лекарство']\n",
      "перенос иметь --- ['непереносимость']\n",
      "ампулы --- ['ампула']\n",
      "дел --- ['гель']\n",
      "концентрат --- ['концентрат']\n",
      "или --- ['релиф']\n",
      "ссср --- ['ЧСС', 'чсс']\n",
      "экг --- ['ЭКГ', 'экг']\n",
      "физ милиция --- ['фибрилляция']\n",
      "же точек --- ['желудочек']\n",
      "крон --- ['хронический']\n",
      "господин --- ['гиподинамический']\n",
      "черный --- ['нервный']\n",
      "сист --- ['система']\n",
      "диагностика --- ['диагностика']\n",
      "гипоксии --- ['гипоксемия']\n",
      "ледокол --- ['лидокаин']\n",
      "блока о --- ['блокатор']\n",
      "такая для --- ['тахикардия']\n",
      "малины наивный --- ['малоинвазивный']\n",
      "акация --- ['аблация', 'абляция']\n",
      "им --- ['ИМ', 'им']\n",
      "поражение --- ['поражение']\n",
      "тяжелый --- ['тяжелый']\n",
      "астра пластика --- ['гастропластика']\n",
      "в --- ['вес']\n",
      "летний --- ['лишний']\n",
      "сорта --- ['аорта']\n",
      "клапан --- ['клапан']\n",
      "сент --- ['вена']\n",
      "малый --- ['полый']\n",
      "пи ричард --- ['перикард']\n",
      "центральный --- ['митральный']\n",
      "ультразвук --- ['ультразвук']\n",
      "хирург --- ['хирург']\n",
      "ко диалог --- ['кардиолог']\n",
      "килограмм --- ['килограмм']\n",
      "арене и --- ['акинезия']\n",
      "верхушка --- ['верхушка']\n",
      "печальный --- ['апикальный']\n",
      "сегмент --- ['сегмент']\n",
      "вес --- ['весь']\n",
      "стенка --- ['стенка']\n",
      "и регулярный --- ['циркулярный']\n",
      "средины --- ['срединный']\n",
      "клапаны --- ['клапанный']\n",
      "аппарат --- ['аппарат']\n",
      "патология --- ['патология']\n",
      "перепад --- ['перикард']\n",
      "максимальный --- ['проксимальный']\n",
      "диаметр --- ['диаметр']\n",
      "коррекция --- ['коррекция']\n",
      "наслаждение --- ['осложнение']\n",
      "страдать --- ['страдать']\n",
      "гипертонической --- ['гипертонический']\n",
      "болезни --- ['болезнь']\n",
      "о датировать --- ['адаптировать']\n",
      "получить --- ['получать']\n",
      "консервативный --- ['консервативный']\n",
      "течение --- ['течение']\n",
      "требование --- ['пребывание']\n",
      "отделение --- ['отделение']\n",
      "самочувствие --- ['самочувствие']\n",
      "ухудшение --- ['ухудшение']\n",
      "место --- ['место']\n",
      "функция --- ['пункция']\n",
      "особенность --- ['особенность']\n",
      "шут --- ['шунт']\n",
      "и цитирование --- ['шунтирование']\n",
      "вотчина --- ['гатчина']\n",
      "эх --- ['эхо']\n",
      "кара парный --- ['коронарный']\n",
      "артерия --- ['артерия']\n",
      "значимый --- ['значимый']\n",
      "стихов --- ['стеноз']\n",
      "нас анализировать --- ['госпитализировать']\n",
      "имя --- ['имя']\n",
      "алмазов --- ['алмазов']\n",
      "предшествовать --- ['предшествовать']\n",
      "истина партия --- ['стенокардия']\n",
      "принести --- ['перенести']\n",
      "инфаркт --- ['инфаркт']\n",
      "миокарда --- ['миокарда']\n",
      "локализация --- ['локализация']\n",
      "справка --- ['справка']\n",
      "дальнейшей --- ['дальнейший']\n",
      "хроническая недостаточность --- ['хроническая недостаточность', 'хронический недостаточность']\n",
      "инфаркт миокарда --- ['инфаркт миокарда', 'инфаркт миокард']\n",
      "от зла --- ['от узла', 'от узел']\n",
      "нарушение работы --- ['нарушение работы', 'нарушение работа']\n",
      "минуту --- ['в минуту', 'в минута', 'минута']\n",
      "эндокринной системы --- ['эндокринная система', 'эндокринный система']\n",
      "сердечный ритм --- ['сердечный ритм']\n",
      "узловаятахикардия --- ['узловая тахикардия', 'узловой тахикардия']\n",
      "основные факторы --- ['основной факто', 'основные факторы']\n",
      "остановка сердца --- ['остановка сердца', 'остановка сердце']\n",
      "фибрилляцияжелудочков --- ['фибрилляция желудочков', 'фибрилляция желудочек']\n",
      "частотой --- ['с частотой', 'с частотаб частота']\n",
      "Right corrected words count - 92 of 200 total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_result_precision(test_word_list, test_symspell_py_lookup_compound_result[\"corrected_word_list\"], test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Spellchecker_tests.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}