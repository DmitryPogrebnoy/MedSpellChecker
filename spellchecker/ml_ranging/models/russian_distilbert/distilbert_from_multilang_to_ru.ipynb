{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from regex import regex\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM, pipeline\n",
    "import json\n",
    "import os\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# There is no uncased multilang distilbert\n",
    "MULTILANG_DISTILBERT_CHECKPOINT = \"distilbert-base-multilingual-cased\"\n",
    "\n",
    "RUSSIAN_DISTILBERT_CHECKPOINT = \"distilbert-base-russian-cased\"\n",
    "\n",
    "PATH_TO_NEW_MODEL = \"../../../../data/ml/distilbert_russian/model\"\n",
    "PATH_TO_NEW_TOKENIZER = \"../../../../data/ml/distilbert_russian/tokenizer\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial distilbert vocab size: 119547\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "multilang_tokenizer = DistilBertTokenizer.from_pretrained(MULTILANG_DISTILBERT_CHECKPOINT)\n",
    "multilang_vocab = list(multilang_tokenizer.vocab.keys())\n",
    "print(f\"Initial distilbert vocab size: {len(multilang_vocab)}\")\n",
    "print(f\"{multilang_tokenizer.bos_token}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "REGEXP_FOR_SPECIAL_TOKENS = \"\\[.*\\]\"\n",
    "REGEXP_FOR_UNUSED_TOKENS = \"\\[unused\\d+\\]\"\n",
    "REGEXP_FOR_RUSSIAN_WORDPIECE = \"#*[аАбБвВгГдДеЕёЁжЖзЗиИйЙкКлЛмМнНоОпПрРсСтТуУфФхХцЦчЧшШщЩъЪыЫьЬэЭюЮяЯ]*\"\n",
    "REGEXP_FOR_FULL_HASHTAG_PIECE = \"#+\"\n",
    "REGEXP_FOR_PUNCTUATION = \"\\p{Punct}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "['[PAD]',\n '[unused1]',\n '[unused2]',\n '[unused3]',\n '[unused4]',\n '[unused5]',\n '[unused6]',\n '[unused7]',\n '[unused8]',\n '[unused9]',\n '[unused10]',\n '[unused11]',\n '[unused12]',\n '[unused13]',\n '[unused14]',\n '[unused15]',\n '[unused16]',\n '[unused17]',\n '[unused18]',\n '[unused19]',\n '[unused20]',\n '[unused21]',\n '[unused22]',\n '[unused23]',\n '[unused24]',\n '[unused25]',\n '[unused26]',\n '[unused27]',\n '[unused28]',\n '[unused29]',\n '[unused30]',\n '[unused31]',\n '[unused32]',\n '[unused33]',\n '[unused34]',\n '[unused35]',\n '[unused36]',\n '[unused37]',\n '[unused38]',\n '[unused39]',\n '[unused40]',\n '[unused41]',\n '[unused42]',\n '[unused43]',\n '[unused44]',\n '[unused45]',\n '[unused46]',\n '[unused47]',\n '[unused48]',\n '[unused49]',\n '[unused50]',\n '[unused51]',\n '[unused52]',\n '[unused53]',\n '[unused54]',\n '[unused55]',\n '[unused56]',\n '[unused57]',\n '[unused58]',\n '[unused59]',\n '[unused60]',\n '[unused61]',\n '[unused62]',\n '[unused63]',\n '[unused64]',\n '[unused65]',\n '[unused66]',\n '[unused67]',\n '[unused68]',\n '[unused69]',\n '[unused70]',\n '[unused71]',\n '[unused72]',\n '[unused73]',\n '[unused74]',\n '[unused75]',\n '[unused76]',\n '[unused77]',\n '[unused78]',\n '[unused79]',\n '[unused80]',\n '[unused81]',\n '[unused82]',\n '[unused83]',\n '[unused84]',\n '[unused85]',\n '[unused86]',\n '[unused87]',\n '[unused88]',\n '[unused89]',\n '[unused90]',\n '[unused91]',\n '[unused92]',\n '[unused93]',\n '[unused94]',\n '[unused95]',\n '[unused96]',\n '[unused97]',\n '[unused98]',\n '[unused99]',\n '[UNK]',\n '[CLS]',\n '[SEP]',\n '[MASK]',\n '!',\n '\"',\n '#',\n '%',\n '&',\n \"'\",\n '(',\n ')',\n '*',\n ',',\n '-',\n '.',\n '/',\n ':',\n ';',\n '?',\n '@',\n '[',\n '\\\\',\n ']',\n '_',\n '{',\n '}',\n '¡',\n '§',\n '«',\n '¶',\n '·',\n '»',\n '¿',\n 'Ё',\n 'А',\n 'Б',\n 'В',\n 'Г',\n 'Д',\n 'Е',\n 'Ж',\n 'З',\n 'И',\n 'Й',\n 'К',\n 'Л',\n 'М',\n 'Н',\n 'О',\n 'П',\n 'Р',\n 'С',\n 'Т',\n 'У',\n 'Ф',\n 'Х',\n 'Ц',\n 'Ч',\n 'Ш',\n 'Щ',\n 'Ъ',\n 'Ы',\n 'Ь',\n 'Э',\n 'Ю',\n 'Я',\n 'а',\n 'б',\n 'в',\n 'г',\n 'д',\n 'е',\n 'ж',\n 'з',\n 'и',\n 'й',\n 'к',\n 'л',\n 'м',\n 'н',\n 'о',\n 'п',\n 'р',\n 'с',\n 'т',\n 'у',\n 'ф',\n 'х',\n 'ц',\n 'ч',\n 'ш',\n 'щ',\n 'ъ',\n 'ы',\n 'ь',\n 'э',\n 'ю',\n 'я',\n 'ё',\n '՚',\n '՛',\n '՜',\n '՝',\n '՞',\n '։',\n '֊',\n '־',\n '׃',\n '׳',\n '״',\n '،',\n '؍',\n '؛',\n '؟',\n '٪',\n '٫',\n '٬',\n '٭',\n '۔',\n '।',\n '॥',\n '॰',\n '་',\n '།',\n '၊',\n '။',\n '၌',\n '၍',\n '၎',\n '၏',\n '‖',\n '‚',\n '„',\n '‟',\n '†',\n '‡',\n '•',\n '․',\n '‥',\n '‧',\n '‰',\n '′',\n '″',\n '‹',\n '›',\n '※',\n '‿',\n '⁾',\n '₍',\n '₎',\n '〈',\n '〉',\n '⟨',\n '⟩',\n '、',\n '。',\n '〃',\n '〈',\n '〉',\n '《',\n '》',\n '「',\n '」',\n '『',\n '』',\n '【',\n '】',\n '〔',\n '〕',\n '〖',\n '〗',\n '〜',\n '〝',\n '・',\n '﴾',\n '﴿',\n '︰',\n '﹐',\n '﹑',\n '﹔',\n '﹕',\n '﹝',\n '﹞',\n '﹣',\n '！',\n '＂',\n '＃',\n '％',\n '＆',\n '（',\n '）',\n '＊',\n '，',\n '－',\n '．',\n '／',\n '：',\n '；',\n '？',\n '＠',\n '［',\n '＼',\n '］',\n '＿',\n '｡',\n '｢',\n '｣',\n '､',\n '･',\n 'на',\n '##а',\n '##и',\n '##е',\n '##у',\n 'за',\n '##м',\n '##н',\n 'се',\n '##ы',\n 'по',\n '##о',\n 'от',\n 'года',\n 'до',\n '##т',\n '##х',\n '##ом',\n '##та',\n 'не',\n '##й',\n '##я',\n 'из',\n 'да',\n '##на',\n 'од',\n '##ов',\n 'во',\n 'та',\n 'году',\n '##ми',\n '##к',\n '##с',\n '##л',\n '##р',\n 'для',\n '##ка',\n '##в',\n 'су',\n '##ю',\n '##ся',\n '##но',\n '##ки',\n '##ни',\n '##ла',\n '##не',\n '##те',\n 'был',\n 'року',\n '##д',\n '##то',\n 'На',\n 'км',\n '##ли',\n 'что',\n '##г',\n '##ь',\n '##ва',\n 'що',\n 'са',\n 'или',\n 'при',\n '##ен',\n 'его',\n 'как',\n 'со',\n '##ти',\n '##ных',\n '##да',\n '##го',\n '##ма',\n 'године',\n '##от',\n 'англ',\n '##ного',\n 'он',\n '##ной',\n '##п',\n '##ра',\n '##ный',\n '##ской',\n '##ш',\n '##ского',\n '##ку',\n '##ные',\n 'година',\n '##ан',\n '##ть',\n 'но',\n '##ой',\n '##ны',\n 'де',\n '##га',\n 'як',\n '##ский',\n 'под',\n 'области',\n '##ски',\n 'также',\n 'была',\n 'становника',\n '##ца',\n 'По',\n '##них',\n 'го',\n '##ия',\n '##ний',\n '##ная',\n '##ий',\n 'Кхузахь',\n '##ке',\n '##ст',\n '##з',\n 'ду',\n '##он',\n 'было',\n '##ло',\n '##ет',\n '##ко',\n 'были',\n 'время',\n 'то',\n '##ным',\n 'коды',\n 'За',\n 'што',\n '##ник',\n '##ей',\n '##ч',\n '##ну',\n '##ри',\n '##му',\n 'же',\n 'дар',\n '##сь',\n '##ле',\n '##ды',\n '##ок',\n '##ии',\n 'после',\n 'було',\n 'село',\n 'год',\n '##ер',\n '##ская',\n 'налази',\n 'населения',\n '##ци',\n '##са',\n '##ова',\n '##ж',\n '##ин',\n 'був',\n '##ами',\n 'их',\n 'РФ',\n 'като',\n 'Према',\n 'юкъа',\n '##сы',\n 'його',\n 'през',\n '##ль',\n '##ын',\n 'так',\n 'России',\n '##ском',\n '##ц',\n '##ска',\n '##сти',\n '##ты',\n '##ство',\n 'где',\n 'СССР',\n '##де',\n '##ния',\n '##ського',\n '##ства',\n 'жана',\n 'живело',\n '##ою',\n '##ат',\n 'хуьлу',\n 'му',\n 'эвла',\n '##ном',\n 'того',\n 'висини',\n 'том',\n '##ских',\n 'ва',\n '##ого',\n 'буенча',\n 'два',\n 'бассейны',\n '##б',\n 'областан',\n '##ции',\n 'час',\n '##ем',\n '##ах',\n 'над',\n '##ное',\n 'Во',\n 'аса',\n 'па',\n 'бойынша',\n 'си',\n 'како',\n '##ге',\n '##ите',\n '##ие',\n 'её',\n 'држави',\n 'про',\n '##ную',\n 'або',\n '##сть',\n '##ал',\n 'општини',\n '##ня',\n '##ди',\n 'Сахьтан',\n '##ар',\n 'лет',\n 'США',\n 'була',\n 'через',\n '##ту',\n 'нь',\n 'После',\n 'као',\n 'сахьт',\n '##ых',\n '##ена',\n 'також',\n '##ць',\n '##нда',\n 'индексаш',\n '##ський',\n '##ция',\n 'буйынса',\n 'который',\n 'има',\n '##цы',\n 'это',\n '##их',\n 'без',\n 'Русия',\n 'подацима',\n 'нийса',\n 'климат',\n 'лелаш',\n '##ча',\n '##ков',\n 'може',\n '##ят',\n 'були',\n '##ор',\n 'более',\n '##се',\n '##ним',\n '##ина',\n '##ам',\n 'але',\n 'человек',\n '##лар',\n 'между',\n '##ша',\n 'об',\n 'три',\n '##лы',\n '##ев',\n '##це',\n 'место',\n '##ры',\n 'им',\n '##ната',\n '##ът',\n 'оьрс',\n '##ба',\n '##ше',\n '##ком',\n 'является',\n 'аз',\n '##ил',\n 'стал',\n '##им',\n '##ым',\n 'против',\n 'який',\n 'През',\n 'реестры',\n '##ел',\n '##ши',\n '##ние',\n 'января',\n 'саны',\n '##ию',\n '##ско',\n 'шп',\n 'ба',\n 'Российн',\n '##ф',\n '##за',\n 'Федерацин',\n 'те',\n 'них',\n 'Мексику',\n 'време',\n 'жылы',\n '##би',\n 'мен',\n 'все',\n '##си',\n 'состав',\n 'один',\n '##ют',\n 'только',\n 'около',\n '##тар',\n '##ви',\n 'города',\n 'континенталан',\n '##ля',\n 'века',\n '##ните',\n '##ый',\n '##че',\n 'войны',\n '##ында',\n 'лараран',\n 'микрохаамаш',\n 'она',\n 'него',\n 'которые',\n '##ника',\n 'мая',\n 'населення',\n '##ги',\n 'барамера',\n 'шеран',\n '##ться',\n '##ве',\n 'августа',\n '##чи',\n 'шш',\n 'рус',\n 'шийла',\n 'района',\n 'они',\n '##ген',\n '##скан',\n '##ро',\n '##ется',\n 'При',\n 'той',\n '##ре',\n '##ными',\n '##ские',\n '##ру',\n '##кой',\n '##мен',\n '##ман',\n '##ик',\n 'елга',\n 'До',\n 'Российской',\n 'этого',\n '##ске',\n 'мм',\n 'био',\n 'марта',\n '##ович',\n 'Климат',\n 'этом',\n 'Москваца',\n 'части',\n 'реки',\n '##йн',\n '##ые',\n 'села',\n 'менен',\n 'йовха',\n '##ую',\n '##она',\n 'Кеп',\n '##ана',\n '##вання',\n '##ая',\n 'район',\n '##ння',\n '##ское',\n '##ме',\n 'била',\n 'Он',\n 'ки',\n 'декабря',\n '##К',\n 'град',\n 'бар',\n '##чно',\n '##ения',\n '##ено',\n 'июля',\n '##С',\n '##ська',\n 'бил',\n '##ган',\n 'че',\n '##ють',\n 'само',\n 'составе',\n '##зи',\n 'две',\n 'Республики',\n '##ск',\n '##ера',\n 'годах',\n '##жи',\n 'июня',\n '##чки',\n 'сентября',\n 'октября',\n 'ред',\n '##тан',\n '##ени',\n '##ската',\n 'свою',\n '##чка',\n '##па',\n '##дан',\n '##ика',\n 'апреля',\n 'округу',\n '##нь',\n '##во',\n '##лары',\n 'тому',\n 'когда',\n '##нан',\n 'код',\n 'жер',\n 'стала',\n 'години',\n 'мира',\n 'фр',\n '##ить',\n 'энциклопедия',\n 'Федерации',\n '##чна',\n '##ших',\n 'фон',\n 'ноября',\n '##тер',\n 'Численность',\n 'которых',\n '##ала',\n '##гу',\n 'уже',\n '##ста',\n '##ща',\n '##ню',\n '##ному',\n 'Москва',\n 'генерал',\n 'других',\n '##ья',\n 'ад',\n 'гг',\n 'барамехь',\n 'шыв',\n 'ги',\n '##мы',\n 'наук',\n 'Для',\n '##ови',\n 'чтобы',\n '##али',\n 'це',\n '##ына',\n '##ности',\n '##зе',\n '##ров',\n 'други',\n 'годы',\n '##ек',\n '##лык',\n '##ит',\n 'центр',\n 'февраля',\n 'часть',\n 'территории',\n 'най',\n 'Сан',\n 'ст',\n 'истории',\n '##же',\n '##ским',\n 'районе',\n 'годзе',\n 'към',\n 'несколько',\n '##ду',\n 'период',\n '##скую',\n '##П',\n '##ове',\n 'които',\n 'Населення',\n 'това',\n 'ещё',\n 'может',\n 'било',\n '##лу',\n 'вид',\n '##лен',\n 'век',\n '##дар',\n 'адам',\n '##ха',\n '##цию',\n 'которой',\n 'клуб',\n '##ение',\n 'след',\n 'день',\n 'получил',\n 'много',\n '##ини',\n '##ських',\n 'урнашкан',\n '##ран',\n '##ось',\n 'който',\n '##шы',\n 'дека',\n '##су',\n 'би',\n '##сон',\n 'яка',\n '##ак',\n 'кои',\n '##ай',\n '##ший',\n '##чу',\n '##тов',\n 'которая',\n 'одного',\n 'др',\n 'см',\n '##чен',\n '##ати',\n 'своей',\n 'область',\n '##ила',\n 'роль',\n 'га',\n '##од',\n 'группы',\n 'участие',\n 'времени',\n '##ун',\n 'став',\n '##ийн',\n '##ара',\n '##ец',\n 'экология',\n '##цев',\n '##ден',\n '##ення',\n '##чних',\n '##цу',\n '##нд',\n '##А',\n '##чы',\n 'двух',\n '##У',\n '##или',\n '##вали',\n 'ще',\n '##эн',\n 'затем',\n 'Алматы',\n 'ему',\n 'городских',\n '##ций',\n '##ческой',\n 'член',\n 'Александр',\n '##ата',\n 'всех',\n '##ней',\n '##кий',\n 'яких',\n '##ол',\n '##лись',\n 'вместе',\n 'себе',\n '##нт',\n 'млн',\n '##ность',\n '##ое',\n 'составляет',\n 'находится',\n 'качестве',\n '##ников',\n '##нето',\n '##ёт',\n '##лся',\n 'нем',\n 'жизни',\n '##нии',\n 'экз',\n '##жа',\n 'раз',\n 'одним',\n 'права',\n 'във',\n '##кан',\n 'среди',\n '##ница',\n 'людей',\n '##ця',\n '##ель',\n 'однако',\n 'стали',\n '##ес',\n 'дел',\n 'город',\n 'род',\n 'складу',\n 'цього',\n 'лат',\n 'Однако',\n 'дорад',\n 'Обь',\n 'Санкт',\n 'аст',\n 'которого',\n '##ются',\n 'имени',\n 'есть',\n 'быть',\n 'близько',\n '##ському',\n 'району',\n 'Бассейн',\n 'така',\n '##ээ',\n 'ул',\n '##ева',\n '##хь',\n 'переписи',\n '##овой',\n '##ники',\n '##има',\n 'армии',\n 'аб',\n '##лер',\n 'числе',\n 'роках',\n 'руск',\n 'чи',\n 'себя',\n 'уггаре',\n 'данным',\n 'яке',\n '##ву',\n '##до',\n '##ён',\n '##ос',\n '##ив',\n 'деревня',\n '##О',\n '##Р',\n 'август',\n 'края',\n 'человека',\n 'городе',\n '##ела',\n '##вала',\n '##ких',\n '##ческих',\n 'этой',\n '##чного',\n '##бе',\n '##чных',\n '##ул',\n 'част',\n ...]"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_vocab = [token for token in multilang_vocab if (regex.fullmatch(\"|\".join([REGEXP_FOR_SPECIAL_TOKENS, REGEXP_FOR_UNUSED_TOKENS, REGEXP_FOR_RUSSIAN_WORDPIECE, REGEXP_FOR_FULL_HASHTAG_PIECE, REGEXP_FOR_PUNCTUATION]), token))]\n",
    "russian_vocab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "russian_num_tokens = len(russian_vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilang distilbert model has 135445755 parameters\n"
     ]
    }
   ],
   "source": [
    "multilang_model = DistilBertForMaskedLM.from_pretrained(MULTILANG_DISTILBERT_CHECKPOINT)\n",
    "print(f\"Multilang distilbert model has {multilang_model.num_parameters()} parameters\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Code partially borrowed from https://github.com/Geotrend-research/smaller-transformers/blob/main/notebooks/select_mBERT_vocabularies.ipynb\n",
    "\n",
    "# Get old embeddings from model\n",
    "multilang_embeddings = multilang_model.get_input_embeddings()\n",
    "multilang_num_tokens,multilang_embedding_dim = multilang_embeddings.weight.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(119547, 768)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilang_num_tokens, multilang_embedding_dim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(11417, 768)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build new embeddings\n",
    "new_embeddings = nn.Embedding(russian_num_tokens, multilang_embedding_dim)\n",
    "new_embeddings.to(multilang_embeddings.weight.device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(11417, 768)\n",
      "Embedding(11417, 768)\n"
     ]
    }
   ],
   "source": [
    "# Copy weights for similar tokens and drop others\n",
    "i = 0\n",
    "j = 0\n",
    "for token in multilang_vocab:\n",
    "    if token in russian_vocab:\n",
    "        new_embeddings.weight.data[i, :] = multilang_embeddings.weight.data[j, :]\n",
    "        i += 1\n",
    "    j += 1\n",
    "\n",
    "multilang_model.set_input_embeddings(new_embeddings)\n",
    "\n",
    "print(multilang_model.get_input_embeddings())\n",
    "\n",
    "# Update base model and current model config\n",
    "multilang_model.config.vocab_size = russian_num_tokens\n",
    "multilang_model.vocab_size = russian_num_tokens\n",
    "\n",
    "# Tie weights\n",
    "multilang_model.tie_weights()\n",
    "\n",
    "print(multilang_model.get_input_embeddings())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data/ml/distilbert_russian/model  -   num_parameters :  52293785\n",
      "../../../../data/ml/distilbert_russian/model  -   num_tokens :  11417\n"
     ]
    }
   ],
   "source": [
    "# Save new model\n",
    "multilang_model.save_pretrained(PATH_TO_NEW_MODEL)\n",
    "print(PATH_TO_NEW_MODEL, \" - \", \" num_parameters : \", multilang_model.num_parameters())\n",
    "print(PATH_TO_NEW_MODEL, \" - \", \" num_tokens : \", len(russian_vocab))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# Save vocab\n",
    "with open(os.path.join(PATH_TO_NEW_TOKENIZER, 'vocab.txt'), 'w+') as fw:\n",
    "    for token in russian_vocab:\n",
    "        fw.write(token + '\\n')\n",
    "\n",
    "# Save tokenizer config\n",
    "with open(os.path.join(PATH_TO_NEW_TOKENIZER, 'tokenizer_config.json'), 'w+') as fw:\n",
    "    json.dump({\"do_lower_case\": False, \"model_max_length\": 512}, fw)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "russian_tokenizer = DistilBertTokenizer.from_pretrained(PATH_TO_NEW_TOKENIZER)\n",
    "russian_model = DistilBertForMaskedLM.from_pretrained(PATH_TO_NEW_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "52293785"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_model.num_parameters()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(11417, 768, padding_idx=0)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_model.get_input_embeddings()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "PreTrainedTokenizer(name_or_path='../../../../data/ml/distilbert_russian/tokenizer', vocab_size=11417, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# Save and reopen model and tokenizer\n",
    "russian_tokenizer.save_pretrained(PATH_TO_NEW_TOKENIZER)\n",
    "russian_model.save_pretrained(PATH_TO_NEW_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "russian_tokenizer = DistilBertTokenizer.from_pretrained(PATH_TO_NEW_TOKENIZER)\n",
    "russian_model = DistilBertForMaskedLM.from_pretrained(PATH_TO_NEW_MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fast test on example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "text = \"Я люблю [MASK] Россию.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   540,   552, 10593, 61394, 10593,   103, 89043,   119,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "MaskedLMOutput(loss=None, logits=tensor([[[-10.0335, -10.0463, -10.0795,  ...,  -9.7731,  -9.5484,  -9.6199],\n",
      "         [-11.8299, -11.8983, -12.1971,  ..., -10.9337, -10.1853, -10.4831],\n",
      "         [-13.4928, -13.5642, -13.2392,  ..., -11.6357, -11.8119, -11.6546],\n",
      "         ...,\n",
      "         [-10.4157, -10.7096,  -9.9264,  ...,  -9.3829,  -9.3726,  -8.8452],\n",
      "         [-13.7720, -13.6973, -13.0738,  ..., -12.4249, -11.4396, -12.2219],\n",
      "         [-12.2253, -11.8086, -11.6672,  ..., -10.8050, -10.0424, -10.2295]]],\n",
      "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "multilang_model = DistilBertForMaskedLM.from_pretrained(MULTILANG_DISTILBERT_CHECKPOINT)\n",
    "multilang_tokenizer = DistilBertTokenizer.from_pretrained(MULTILANG_DISTILBERT_CHECKPOINT)\n",
    "multilang_encoded_input = multilang_tokenizer(text, return_tensors='pt')\n",
    "print(multilang_encoded_input)\n",
    "multilang_output_original = multilang_model(**multilang_encoded_input)\n",
    "print(multilang_output_original)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101,  166,  178,  349, 5592,  349,  103, 8750,  115,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "MaskedLMOutput(loss=None, logits=tensor([[[-10.0335, -10.0463, -10.0795,  ...,  -3.3749,  -2.9937,  -3.2878],\n",
      "         [-11.8299, -11.8983, -12.1971,  ...,  -0.6611,   0.1207,   3.0330],\n",
      "         [-13.4928, -13.5642, -13.2392,  ...,   1.4186,  -0.5307,   1.6961],\n",
      "         ...,\n",
      "         [-10.4157, -10.7096,  -9.9264,  ...,   0.4886,   1.7815,   2.3896],\n",
      "         [-13.7720, -13.6973, -13.0738,  ...,  -0.1794,   1.1187,   1.2068],\n",
      "         [-12.2253, -11.8086, -11.6672,  ...,   0.2578,   1.5360,   1.5543]]],\n",
      "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "russian_encoded_input = russian_tokenizer(text, return_tensors='pt')\n",
    "print(russian_encoded_input)\n",
    "russian_output_original = russian_model(**russian_encoded_input)\n",
    "print(russian_output_original)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "с в о ю 0.1130324974656105\n",
      "э т у 0.07151170819997787\n",
      "# # ю 0.048914585262537\n",
      "# # с ь 0.04644572734832764\n",
      "в 0.023181308060884476\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task=\"fill-mask\", model=multilang_model, tokenizer=multilang_tokenizer)\n",
    "output_ = pipe(text)\n",
    "for i in range(len(output_)):\n",
    "    print(output_[i]['token_str'], output_[i]['score'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "с в о ю 0.10373394191265106\n",
      "э т у 0.0814199224114418\n",
      "в 0.05354791134595871\n",
      "# # с ь 0.04612283781170845\n",
      "э т о 0.025950049981474876\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task=\"fill-mask\", model=russian_model, tokenizer=russian_tokenizer)\n",
    "output_ = pipe(text)\n",
    "for i in range(len(output_)):\n",
    "    print(output_[i]['token_str'], output_[i]['score'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "geo_model = DistilBertForMaskedLM.from_pretrained(\"Geotrend/distilbert-base-ru-cased\")\n",
    "geo_tokenizer = DistilBertTokenizer.from_pretrained(\"Geotrend/distilbert-base-ru-cased\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "с в о ю 0.11730142682790756\n",
      "э т у 0.08307341486215591\n",
      "# # с ь 0.04491831362247467\n",
      "# # ю 0.03141210600733757\n",
      "я 0.027354605495929718\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(task=\"fill-mask\", model=geo_model, tokenizer=geo_tokenizer)\n",
    "output_ = pipe(text)\n",
    "for i in range(len(output_)):\n",
    "    print(output_[i]['token_str'], output_[i]['score'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we have three distil models (multilang, own and from Geotrend). We need to pick most suitable one.\n",
    "So let's see perplexity metrics on the anamnesis dataset and decide which one is winner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
